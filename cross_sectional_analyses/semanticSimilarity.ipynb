{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "0x4lzcczQDVdXOVrHTiPvt",
     "type": "MD"
    }
   },
   "source": [
    "## Semantic Similarity\n",
    "\n",
    "This notebook walks through the steps to compute word embeddings for each comment in the Reddit dataset. Continuing from the previous notebook, we consider weekly-level data from the months of May and June across the selected subreddits to compute the word embeddings. We utilize an sentence-BERT model using which we compute embeddings and then generate a Semantic Similarity Measure.\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "d7ut32ItEoycnUHqzy4H0Z",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyarrow\r\n",
      "  Downloading pyarrow-16.0.0-cp38-cp38-manylinux_2_28_x86_64.whl (40.8 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/40.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/40.8 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/40.8 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/40.8 MB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/40.8 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/40.8 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/40.8 MB\u001b[0m \u001b[31m100.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.2/40.8 MB\u001b[0m \u001b[31m116.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.0/40.8 MB\u001b[0m \u001b[31m111.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m29.2/40.8 MB\u001b[0m \u001b[31m112.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m33.6/40.8 MB\u001b[0m \u001b[31m118.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m37.6/40.8 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /opt/python/envs/default/lib/python3.8/site-packages (from pyarrow) (1.24.3)\r\n",
      "Installing collected packages: pyarrow\r\n",
      "Successfully installed pyarrow-16.0.0\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "a6284J9DvyUPVXtpZG53sH",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\r\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: click in /opt/python/envs/default/lib/python3.8/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /opt/python/envs/default/lib/python3.8/site-packages (from nltk) (1.4.0)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/python/envs/default/lib/python3.8/site-packages (from nltk) (2024.4.16)\r\n",
      "Requirement already satisfied: tqdm in /opt/python/envs/default/lib/python3.8/site-packages (from nltk) (4.66.2)\r\n",
      "Installing collected packages: nltk\r\n",
      "Successfully installed nltk-3.8.1\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "5tRGP6pam6UGZyFjTgU5RW",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/python/envs/default/lib/python3.8/site-packages (2.7.0)\r\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/python/envs/default/lib/python3.8/site-packages (from sentence-transformers) (4.40.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/python/envs/default/lib/python3.8/site-packages (from sentence-transformers) (4.28.1)\r\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/python/envs/default/lib/python3.8/site-packages (from sentence-transformers) (2.0.1+cu117)\r\n",
      "Requirement already satisfied: numpy in /opt/python/envs/default/lib/python3.8/site-packages (from sentence-transformers) (1.24.3)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/python/envs/default/lib/python3.8/site-packages (from sentence-transformers) (1.2.2)\r\n",
      "Requirement already satisfied: scipy in /opt/python/envs/default/lib/python3.8/site-packages (from sentence-transformers) (1.9.1)\r\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in /opt/python/envs/default/lib/python3.8/site-packages (from sentence-transformers) (0.22.2)\r\n",
      "Requirement already satisfied: Pillow in /opt/python/envs/default/lib/python3.8/site-packages (from sentence-transformers) (10.3.0)\r\n",
      "Requirement already satisfied: filelock in /opt/python/envs/default/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.4)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/python/envs/default/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2024.3.1)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/python/envs/default/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (24.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/python/envs/default/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\r\n",
      "Requirement already satisfied: requests in /opt/python/envs/default/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.30.0)\r\n",
      "Collecting tqdm (from sentence-transformers)\r\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/78.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/python/envs/default/lib/python3.8/site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.11.0)\r\n",
      "Requirement already satisfied: sympy in /opt/python/envs/default/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/python/envs/default/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/python/envs/default/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\r\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/python/envs/default/lib/python3.8/site-packages (from torch>=1.11.0->sentence-transformers) (2.0.0)\r\n",
      "Requirement already satisfied: cmake in /opt/python/envs/default/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.11.0->sentence-transformers) (3.29.2)\r\n",
      "Requirement already satisfied: lit in /opt/python/envs/default/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.11.0->sentence-transformers) (18.1.3)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/python/envs/default/lib/python3.8/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2024.4.16)\r\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/python/envs/default/lib/python3.8/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\r\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/python/envs/default/lib/python3.8/site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/python/envs/default/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (1.4.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/python/envs/default/lib/python3.8/site-packages (from scikit-learn->sentence-transformers) (3.4.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/python/envs/default/lib/python3.8/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/python/envs/default/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/python/envs/default/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.7)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/python/envs/default/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/python/envs/default/lib/python3.8/site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/python/envs/default/lib/python3.8/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\r\n",
      "Installing collected packages: tqdm\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.28.1\r\n",
      "    Uninstalling tqdm-4.28.1:\r\n",
      "      Successfully uninstalled tqdm-4.28.1\r\n",
      "Successfully installed tqdm-4.66.4\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Collecting https://github.com/chengs/tqdm/archive/colab.zip\r\n",
      "  Using cached https://github.com/chengs/tqdm/archive/colab.zip\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hBuilding wheels for collected packages: tqdm\r\n",
      "  Building wheel for tqdm (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for tqdm: filename=tqdm-4.28.1-py2.py3-none-any.whl size=47874 sha256=b5a92152648fdec95a70d620d820513b99cc00434984794bf17ca78c9a317dcf\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-eycluf5i/wheels/a7/30/17/f85112bf3ff9d07da5ef0a111c02e4a86df55d990ce52864cd\r\n",
      "Successfully built tqdm\r\n",
      "Installing collected packages: tqdm\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.66.4\r\n",
      "    Uninstalling tqdm-4.66.4:\r\n",
      "      Successfully uninstalled tqdm-4.66.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "huggingface-hub 0.22.2 requires tqdm>=4.42.1, but you have tqdm 4.28.1 which is incompatible.\r\n",
      "spacy 3.7.4 requires tqdm<5.0.0,>=4.38.0, but you have tqdm 4.28.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed tqdm-4.28.1\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n",
      "Collecting swifter\r\n",
      "  Downloading swifter-1.4.0.tar.gz (1.2 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.0.0 in /opt/python/envs/default/lib/python3.8/site-packages (from swifter) (1.5.3)\r\n",
      "Collecting psutil>=5.6.6 (from swifter)\r\n",
      "  Downloading psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/288.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting dask[dataframe]>=2.10.0 (from swifter)\r\n",
      "  Downloading dask-2023.5.0-py3-none-any.whl (1.2 MB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting tqdm>=4.33.0 (from swifter)\r\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)\r\n",
      "Requirement already satisfied: click>=8.0 in /opt/python/envs/default/lib/python3.8/site-packages (from dask[dataframe]>=2.10.0->swifter) (8.1.7)\r\n",
      "Collecting cloudpickle>=1.5.0 (from dask[dataframe]>=2.10.0->swifter)\r\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\r\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in /opt/python/envs/default/lib/python3.8/site-packages (from dask[dataframe]>=2.10.0->swifter) (2024.3.1)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/python/envs/default/lib/python3.8/site-packages (from dask[dataframe]>=2.10.0->swifter) (24.0)\r\n",
      "Collecting partd>=1.2.0 (from dask[dataframe]>=2.10.0->swifter)\r\n",
      "  Downloading partd-1.4.1-py3-none-any.whl (18 kB)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/python/envs/default/lib/python3.8/site-packages (from dask[dataframe]>=2.10.0->swifter) (6.0.1)\r\n",
      "Collecting toolz>=0.10.0 (from dask[dataframe]>=2.10.0->swifter)\r\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\r\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.13.0 in /opt/python/envs/default/lib/python3.8/site-packages (from dask[dataframe]>=2.10.0->swifter) (7.1.0)\r\n",
      "Requirement already satisfied: numpy>=1.21 in /opt/python/envs/default/lib/python3.8/site-packages (from dask[dataframe]>=2.10.0->swifter) (1.24.3)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /opt/python/envs/default/lib/python3.8/site-packages (from pandas>=1.0.0->swifter) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/python/envs/default/lib/python3.8/site-packages (from pandas>=1.0.0->swifter) (2024.1)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/python/envs/default/lib/python3.8/site-packages (from importlib-metadata>=4.13.0->dask[dataframe]>=2.10.0->swifter) (3.18.1)\r\n",
      "Collecting locket (from partd>=1.2.0->dask[dataframe]>=2.10.0->swifter)\r\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/python/envs/default/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas>=1.0.0->swifter) (1.16.0)\r\n",
      "Building wheels for collected packages: swifter\r\n",
      "  Building wheel for swifter (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for swifter: filename=swifter-1.4.0-py3-none-any.whl size=16507 sha256=4284e87cb555fcafd7aed0017aa459456925050cdcc13ece850eede7fb317d0d\r\n",
      "  Stored in directory: /home/datalore/.cache/pip/wheels/86/c2/17/58370efa4aaa58f50055499d12379d806b3b5dd8579d4c33e4\r\n",
      "Successfully built swifter\r\n",
      "Installing collected packages: tqdm, toolz, psutil, locket, cloudpickle, partd, dask, swifter\r\n",
      "  Attempting uninstall: tqdm\r\n",
      "    Found existing installation: tqdm 4.28.1\r\n",
      "    Uninstalling tqdm-4.28.1:\r\n",
      "      Successfully uninstalled tqdm-4.28.1\r\n",
      "Successfully installed cloudpickle-3.0.0 dask-2023.5.0 locket-1.0.0 partd-1.4.1 psutil-5.9.8 swifter-1.4.0 toolz-0.12.1 tqdm-4.66.4\r\n",
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#Download the SBERT model to deploy on the 'body' and the 'receiver_body' columns, so that the word embeddings can be obtained.\n",
    "!pip install -U sentence-transformers\n",
    "# load tqdm\n",
    "!pip install --force https://github.com/chengs/tqdm/archive/colab.zip\n",
    "!pip install swifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "YgMUUCS2dC1ZYxMNXgL3aw",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/datalore/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer, SentencesDataset, InputExample, losses, util\n",
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import losses\n",
    "import os\n",
    "import swifter\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import torch\n",
    "nltk.download('punkt')\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "fiPjHrJhx6dq0IHB4a2WHx",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0de70866994739971e3f7e078674d4",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "datalore": {
        "widget_id": "rSapRD5aXKRdriXvVp8G5G"
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "577d1e3b563b43d1932adf46da2934f7",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "datalore": {
        "widget_id": "RFJTAlXVslyTxjjEPR58WG"
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c884a661c5c7479daaf5ff331f5e85c3",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "datalore": {
        "widget_id": "WD66RlqQJBUMxYQurz9ilO"
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec0af3ab9f349f5a639093e75ffd6cf",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "datalore": {
        "widget_id": "1MrgZZbdZOG74rHZvGlm0C"
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c15ddce476eb46f9b5781eb6ceb15670",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "datalore": {
        "widget_id": "aw7OZO4Gg35kLv7iX1mN4r"
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a067d9a1cf3c4f4eae16d919e17c29a5",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "datalore": {
        "widget_id": "0McjyDlqwsUCLJ5vN5LqrZ"
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c60928bd0c5941c9bc4f2efbd64ffb89",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "datalore": {
        "widget_id": "8gsg9Efr4cj4eN6bWOgMdg"
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add88b582fdb4d7ea32fefef87f80f87",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "datalore": {
        "widget_id": "MR6Ct8poXA6inagyXkU6lQ"
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa86159e798a4c54957a255a5c9e3efa",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "datalore": {
        "widget_id": "xikuILfdIRrPmPmBkMuWFJ"
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693f8e5b00d44e138cd4c9225fd31ead",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "datalore": {
        "widget_id": "5Kq0loQio3bQXmO5NS3fJ6"
       }
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc0b907abac4f9680c2226a9b8cb14f",
       "version_major": 2,
       "version_minor": 0
      }
     },
     "metadata": {
      "application/vnd.jupyter.widget-view+json": {
       "datalore": {
        "widget_id": "bwP31d7nvMfnXGMgrRWG8e"
       }
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define functions to generate the word embeddings at the comment level for each week of data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_language_similarity(val1, val2):\n",
    "    return util.dot_score(val1, val2)\n",
    "\n",
    "#define function to generate embeddings for one row\n",
    "def generate_embeddings(record):\n",
    "   return sbert_model.encode(record, convert_to_numpy=True, normalize_embeddings=True)\n",
    "\n",
    "def divide_data_3_parts(week_data):\n",
    "    \"\"\"\n",
    "    Divide the data of a given week into three parts\n",
    "    Parameters\n",
    "    ----------\n",
    "    week_data : dataframe\n",
    "        the data for a given week\n",
    "    Returns\n",
    "    ----------\n",
    "    part1, part2, part3: tuple of dataframes\n",
    "         the data for each part\n",
    "    \"\"\"\n",
    "    week_data.head(3)\n",
    "    div, mod = divmod(len(week_data), 3)\n",
    "    part1 = week_data[:div]\n",
    "    part2 = week_data[div:div * 2]\n",
    "    part3 = week_data[div * 2:]\n",
    "    if mod == 1:\n",
    "        part3 = pd.concat([part3, part2.iloc[-1:]], ignore_index=True)\n",
    "        part2 = part2.iloc[:-1]\n",
    "    elif mod == 2:\n",
    "        part3 = pd.concat([part3, part2.iloc[-2:]], ignore_index=True)\n",
    "        part2 = part2.iloc[:-2]\n",
    "    return part1, part2, part3\n",
    "\n",
    "def word_embeddings(week_no,part_data,part_no):\n",
    "    \"\"\"\n",
    "    Compute the word embeddings for each author's and receiver's comment and then compute the semantic similarity\n",
    "    Parameters\n",
    "    ----------\n",
    "    week_no : int\n",
    "        the week's number (from 1 to 26)\n",
    "    part_data : dataframe\n",
    "        the subset of the reddit data for the given week\n",
    "    part_no : int\n",
    "        the part number (1, 2, or 3)\n",
    "    Returns\n",
    "    ----------\n",
    "        None\n",
    "    \"\"\"\n",
    "    #call the function to generate word embeddings\n",
    "    print('start generating the word embeddings')\n",
    "    body_embeddings = part_data['body'].progress_apply(generate_embeddings)\n",
    "    print('finished generation of body embeddings')\n",
    "    print(len(body_embeddings))\n",
    "    receiver_body_embeddings = part_data['receiver_body'].progress_apply(generate_embeddings)\n",
    "    print('finished generation of receiver embeddings')\n",
    "    print(len(receiver_body_embeddings))\n",
    "    print('finished generation of word embeddings')\n",
    "    model_storage_name_location = 'word_embeddings/embeddings_w'+ str(week_no) +'_part'+str(part_no)+ '.pkl'\n",
    "    # Open the file in binary write mode\n",
    "    with open(model_storage_name_location, 'wb') as f:\n",
    "        pickle.dump(body_embeddings, f)\n",
    "    print(type(body_embeddings))\n",
    "    model_storage_name_location_receiver = 'word_embeddings/receiver_embeddings_w'+ str(week_no) +'_part'+str(part_no)+ '.pkl'\n",
    "    # Open the file in binary write mode\n",
    "    with open(model_storage_name_location_receiver, 'wb') as f:\n",
    "        pickle.dump(receiver_body_embeddings, f)\n",
    "    print(type(receiver_body_embeddings))\n",
    "    #compute the languageSimilarity\n",
    "    df1 = pd.concat([body_embeddings, receiver_body_embeddings], axis=1)\n",
    "    print(len(df1))\n",
    "    df1['languageSimilarity_commentLevel'] = df1.progress_apply(lambda x: (util.dot_score(x[0],x[1])).item(), axis=1)\n",
    "    extracted_col = df1['languageSimilarity_commentLevel']\n",
    "    print(len(extracted_col))\n",
    "    part_data_final = pd.concat([part_data, extracted_col], axis=1)\n",
    "    print(len(part_data_final))\n",
    "    #part_data_final.head(3)\n",
    "    resulting_file_name = 'bothSim_Processed/mayjune_w'+str(week_no)+'_part'+str(part_no)+ '_processed.parquet'\n",
    "    part_data_final.to_parquet(resulting_file_name)\n",
    "    print('completed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "56iWzJdO5gItjUz0ZOL1Fr",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "##############################\n",
    "#read the embeddings\n",
    "# week = 1\n",
    "# part = 3\n",
    "# body_embeddings_1 = pd.read_pickle('JanFebSubreddits2022/word_embeddings/embeddings_w'+str(week)+'_part'+str(part)+'.pkl')\n",
    "# print(len(body_embeddings_1))\n",
    "# print(body_embeddings_1[0])\n",
    "# print(type(body_embeddings_1))\n",
    "# receiver_embeddings_1 = pd.read_pickle('JanFebSubreddits2022/word_embeddings/receiver_embeddings_w'+str(week)+'_part'+str(part)+'.pkl')\n",
    "# print(len(receiver_embeddings_1))\n",
    "# print(receiver_embeddings_1[0])\n",
    "# print(type(receiver_embeddings_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "vjoRhJC2z5fJ83YWGzyADV",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "#############################\n",
    "#read the processed file with both network similarity and language similarity\n",
    "# week = 1\n",
    "# part = 3\n",
    "# file_path1 = 'JanFebSubreddits2022/bothSim_Processed/janfeb_w' + str(week) + '_part'+str(part)+'_processed.parquet'\n",
    "# week_data2 = pd.read_parquet(file_path1)\n",
    "# print(week_data2['subreddit'].value_counts())\n",
    "# print(week_data2['date'].value_counts())\n",
    "# week_data2.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate, we show how we call the functions to generate word embeddings and hence a semantic similarity measure using the above functions, for a subset of data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "QdhzvzCode9hE0Rc0oWZbm",
     "type": "MD"
    }
   },
   "source": [
    "## Process Week 18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "kgtwwNpkOCcLdQWt0FekQb",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1008518\n",
      "336172\n",
      "336170\n",
      "336176\n",
      "1008518\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre>amitheasshole    372661\n",
       "politics         257921\n",
       "worldnews        230104\n",
       "news             118196\n",
       "science           29636\n",
       "Name: subreddit, dtype: int64</pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#reading the data and dividing it into parts\n",
    "w18 = pd.read_parquet('netSim_processed/mayjune_w18_processed.parquet')\n",
    "print(len(w18))\n",
    "w18_p1,w18_p2,w18_p3 = divide_data_3_parts(w18)\n",
    "print(len(w18_p1))\n",
    "print(len(w18_p2))\n",
    "print(len(w18_p3))\n",
    "print(len(w18_p1)+len(w18_p2)+len(w18_p3))\n",
    "w18['subreddit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "V4D4kQSdfjzf6cSaxg70N9",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>2022-05-03    222768\n",
       "2022-05-04    162014\n",
       "2022-05-02    144216\n",
       "2022-05-05    140083\n",
       "2022-05-06    139102\n",
       "2022-05-07    117116\n",
       "2022-05-01     83219\n",
       "Name: date, dtype: int64</pre>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "w18['date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "NG6sGX0XIxYxbaSDILC3Kq",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "#w18.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "DAvsXwDdOi2W3qEx0RIHxp",
     "type": "CODE"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start generating the word embeddings\n",
      "finished generation of body embeddings\n",
      "336172\n",
      "finished generation of receiver embeddings\n",
      "336172\n",
      "finished generation of word embeddings\n",
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "336172\n",
      "336172\n",
      "336172\n",
      "completed!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/336172 [00:00<?, ?it/s]\r",
      "  0%|          | 1144/336172 [00:00<00:29, 11431.59it/s]\r",
      "  1%|          | 2288/336172 [00:00<00:50, 6670.14it/s] \r",
      "  1%|          | 3075/336172 [00:00<00:47, 7064.49it/s]\r",
      "  1%|▏         | 4418/336172 [00:00<00:36, 9098.34it/s]\r",
      "  2%|▏         | 5788/336172 [00:00<00:31, 10540.40it/s]\r",
      "  2%|▏         | 7102/336172 [00:00<00:29, 11343.04it/s]\r",
      "  2%|▏         | 8397/336172 [00:00<00:27, 11835.27it/s]\r",
      "  3%|▎         | 9626/336172 [00:00<00:30, 10590.69it/s]\r",
      "  3%|▎         | 10986/336172 [00:01<00:28, 11426.34it/s]\r",
      "  4%|▎         | 12238/336172 [00:01<00:27, 11735.09it/s]\r",
      "  4%|▍         | 13620/336172 [00:01<00:26, 12335.08it/s]\r",
      "  4%|▍         | 15098/336172 [00:01<00:24, 13046.67it/s]\r",
      "  5%|▍         | 16426/336172 [00:01<00:24, 13112.74it/s]\r",
      "  5%|▌         | 17792/336172 [00:01<00:23, 13271.66it/s]\r",
      "  6%|▌         | 19189/336172 [00:01<00:23, 13478.83it/s]\r",
      "  6%|▌         | 20577/336172 [00:01<00:23, 13595.38it/s]\r",
      "  7%|▋         | 22040/336172 [00:01<00:22, 13902.66it/s]\r",
      "  7%|▋         | 24106/336172 [00:01<00:19, 15921.88it/s]\r",
      "  8%|▊         | 26116/336172 [00:02<00:18, 17169.97it/s]\r",
      "  8%|▊         | 28189/336172 [00:02<00:16, 18233.83it/s]\r",
      "  9%|▉         | 30280/336172 [00:02<00:16, 19034.04it/s]\r",
      " 10%|▉         | 32378/336172 [00:02<00:15, 19614.55it/s]\r",
      " 10%|█         | 34475/336172 [00:02<00:15, 20018.28it/s]\r",
      " 11%|█         | 36577/336172 [00:02<00:14, 20316.73it/s]\r",
      " 11%|█▏        | 38649/336172 [00:02<00:14, 20435.32it/s]\r",
      " 12%|█▏        | 40743/336172 [00:02<00:14, 20586.47it/s]\r",
      " 13%|█▎        | 42803/336172 [00:02<00:14, 20530.33it/s]\r",
      " 13%|█▎        | 44866/336172 [00:02<00:14, 20558.63it/s]\r",
      " 14%|█▍        | 46970/336172 [00:03<00:13, 20701.70it/s]\r",
      " 15%|█▍        | 49073/336172 [00:03<00:13, 20797.95it/s]\r",
      " 15%|█▌        | 51153/336172 [00:03<00:13, 20736.57it/s]\r",
      " 16%|█▌        | 53238/336172 [00:03<00:13, 20769.00it/s]\r",
      " 16%|█▋        | 55334/336172 [00:03<00:13, 20823.28it/s]\r",
      " 17%|█▋        | 57417/336172 [00:03<00:13, 20761.67it/s]\r",
      " 18%|█▊        | 59494/336172 [00:03<00:13, 20707.42it/s]\r",
      " 18%|█▊        | 61565/336172 [00:03<00:13, 20614.58it/s]\r",
      " 19%|█▉        | 63627/336172 [00:03<00:13, 20512.23it/s]\r",
      " 20%|█▉        | 65679/336172 [00:03<00:13, 20484.41it/s]\r",
      " 20%|██        | 67772/336172 [00:04<00:13, 20614.50it/s]\r",
      " 21%|██        | 69834/336172 [00:04<00:12, 20597.21it/s]\r",
      " 21%|██▏       | 71894/336172 [00:04<00:12, 20581.74it/s]\r",
      " 22%|██▏       | 73988/336172 [00:04<00:12, 20687.77it/s]\r",
      " 23%|██▎       | 76057/336172 [00:04<00:12, 20643.97it/s]\r",
      " 23%|██▎       | 78122/336172 [00:04<00:12, 20477.82it/s]\r",
      " 24%|██▍       | 80179/336172 [00:04<00:12, 20504.88it/s]\r",
      " 24%|██▍       | 82269/336172 [00:04<00:12, 20620.76it/s]\r",
      " 25%|██▌       | 84334/336172 [00:04<00:12, 20627.36it/s]\r",
      " 26%|██▌       | 86407/336172 [00:04<00:12, 20657.58it/s]\r",
      " 26%|██▋       | 88473/336172 [00:05<00:12, 20392.97it/s]\r",
      " 27%|██▋       | 90578/336172 [00:05<00:11, 20587.15it/s]\r",
      " 28%|██▊       | 92681/336172 [00:05<00:11, 20716.96it/s]\r",
      " 28%|██▊       | 94792/336172 [00:05<00:11, 20832.26it/s]\r",
      " 29%|██▉       | 96900/336172 [00:05<00:11, 20904.27it/s]\r",
      " 29%|██▉       | 99007/336172 [00:05<00:11, 20951.77it/s]\r",
      " 30%|███       | 101111/336172 [00:05<00:11, 20978.09it/s]\r",
      " 31%|███       | 103219/336172 [00:05<00:11, 21008.28it/s]\r",
      " 31%|███▏      | 105320/336172 [00:05<00:10, 20987.60it/s]\r",
      " 32%|███▏      | 107426/336172 [00:05<00:10, 21008.99it/s]\r",
      " 33%|███▎      | 109535/336172 [00:06<00:10, 21030.42it/s]\r",
      " 33%|███▎      | 111639/336172 [00:06<00:10, 20991.35it/s]\r",
      " 34%|███▍      | 113741/336172 [00:06<00:10, 20998.99it/s]\r",
      " 34%|███▍      | 115849/336172 [00:06<00:10, 21022.17it/s]\r",
      " 35%|███▌      | 117952/336172 [00:06<00:10, 21008.00it/s]\r",
      " 36%|███▌      | 120056/336172 [00:06<00:10, 21017.28it/s]\r",
      " 36%|███▋      | 122162/336172 [00:06<00:10, 21029.08it/s]\r",
      " 37%|███▋      | 124265/336172 [00:06<00:10, 21010.02it/s]\r",
      " 38%|███▊      | 126367/336172 [00:06<00:09, 20997.38it/s]\r",
      " 38%|███▊      | 128467/336172 [00:06<00:09, 20983.69it/s]\r",
      " 39%|███▉      | 130571/336172 [00:07<00:09, 20997.96it/s]\r",
      " 39%|███▉      | 132673/336172 [00:07<00:09, 21001.51it/s]\r",
      " 40%|████      | 134774/336172 [00:07<00:09, 20999.83it/s]\r",
      " 41%|████      | 136881/336172 [00:07<00:09, 21018.36it/s]\r",
      " 41%|████▏     | 138993/336172 [00:07<00:09, 21047.56it/s]\r",
      " 42%|████▏     | 141108/336172 [00:07<00:09, 21076.73it/s]\r",
      " 43%|████▎     | 143220/336172 [00:07<00:09, 21089.67it/s]\r",
      " 43%|████▎     | 145330/336172 [00:07<00:09, 21090.84it/s]\r",
      " 44%|████▍     | 147440/336172 [00:07<00:08, 21079.29it/s]\r",
      " 44%|████▍     | 149548/336172 [00:07<00:08, 21050.42it/s]\r",
      " 45%|████▌     | 151657/336172 [00:08<00:08, 21059.83it/s]\r",
      " 46%|████▌     | 153766/336172 [00:08<00:08, 21067.33it/s]\r",
      " 46%|████▋     | 155873/336172 [00:08<00:08, 21054.91it/s]\r",
      " 47%|████▋     | 157992/336172 [00:08<00:08, 21094.68it/s]\r",
      " 48%|████▊     | 160102/336172 [00:08<00:08, 20986.75it/s]\r",
      " 48%|████▊     | 162204/336172 [00:08<00:08, 20996.00it/s]\r",
      " 49%|████▉     | 164305/336172 [00:08<00:08, 20999.58it/s]\r",
      " 50%|████▉     | 166408/336172 [00:08<00:08, 21007.42it/s]\r",
      " 50%|█████     | 168516/336172 [00:08<00:07, 21027.14it/s]\r",
      " 51%|█████     | 170632/336172 [00:08<00:07, 21065.80it/s]\r",
      " 51%|█████▏    | 172739/336172 [00:09<00:07, 21065.27it/s]\r",
      " 52%|█████▏    | 174846/336172 [00:09<00:07, 20574.71it/s]\r",
      " 53%|█████▎    | 176941/336172 [00:09<00:07, 20684.55it/s]\r",
      " 53%|█████▎    | 179043/336172 [00:09<00:07, 20783.10it/s]\r",
      " 54%|█████▍    | 181143/336172 [00:09<00:07, 20847.38it/s]\r",
      " 55%|█████▍    | 183255/336172 [00:09<00:07, 20925.89it/s]\r",
      " 55%|█████▌    | 185356/336172 [00:09<00:07, 20950.29it/s]\r",
      " 56%|█████▌    | 187461/336172 [00:09<00:07, 20977.92it/s]\r",
      " 56%|█████▋    | 189560/336172 [00:09<00:06, 20950.29it/s]\r",
      " 57%|█████▋    | 191660/336172 [00:09<00:06, 20962.24it/s]\r",
      " 58%|█████▊    | 193757/336172 [00:10<00:06, 20963.25it/s]\r",
      " 58%|█████▊    | 195854/336172 [00:10<00:06, 20957.95it/s]\r",
      " 59%|█████▉    | 197950/336172 [00:10<00:06, 20950.17it/s]\r",
      " 60%|█████▉    | 200046/336172 [00:10<00:06, 20948.66it/s]\r",
      " 60%|██████    | 202151/336172 [00:10<00:06, 20978.65it/s]\r",
      " 61%|██████    | 204249/336172 [00:10<00:06, 20966.70it/s]\r",
      " 61%|██████▏   | 206350/336172 [00:10<00:06, 20976.82it/s]\r",
      " 62%|██████▏   | 208448/336172 [00:10<00:06, 20956.20it/s]\r",
      " 63%|██████▎   | 210548/336172 [00:10<00:05, 20966.83it/s]\r",
      " 63%|██████▎   | 212646/336172 [00:10<00:05, 20967.98it/s]\r",
      " 64%|██████▍   | 214751/336172 [00:11<00:05, 20992.00it/s]\r",
      " 65%|██████▍   | 216851/336172 [00:11<00:05, 20975.14it/s]\r",
      " 65%|██████▌   | 218949/336172 [00:11<00:05, 20952.12it/s]\r",
      " 66%|██████▌   | 221054/336172 [00:11<00:05, 20980.80it/s]\r",
      " 66%|██████▋   | 223160/336172 [00:11<00:05, 21003.03it/s]\r",
      " 67%|██████▋   | 225261/336172 [00:11<00:05, 21003.56it/s]\r",
      " 68%|██████▊   | 227363/336172 [00:11<00:05, 21008.18it/s]\r",
      " 68%|██████▊   | 229464/336172 [00:11<00:05, 20977.52it/s]\r",
      " 69%|██████▉   | 231562/336172 [00:11<00:04, 20946.79it/s]\r",
      " 70%|██████▉   | 233657/336172 [00:11<00:04, 20940.72it/s]\r",
      " 70%|███████   | 235758/336172 [00:12<00:04, 20960.50it/s]\r",
      " 71%|███████   | 237857/336172 [00:12<00:04, 20969.14it/s]\r",
      " 71%|███████▏  | 239954/336172 [00:12<00:04, 20957.37it/s]\r",
      " 72%|███████▏  | 242050/336172 [00:12<00:04, 20952.13it/s]\r",
      " 73%|███████▎  | 244146/336172 [00:12<00:04, 20933.15it/s]\r",
      " 73%|███████▎  | 246242/336172 [00:12<00:04, 20939.14it/s]\r",
      " 74%|███████▍  | 248341/336172 [00:12<00:04, 20954.24it/s]\r",
      " 74%|███████▍  | 250437/336172 [00:12<00:04, 20953.65it/s]\r",
      " 75%|███████▌  | 252534/336172 [00:12<00:03, 20955.68it/s]\r",
      " 76%|███████▌  | 254642/336172 [00:12<00:03, 20991.18it/s]\r",
      " 76%|███████▋  | 256745/336172 [00:13<00:03, 21002.12it/s]\r",
      " 77%|███████▋  | 258846/336172 [00:13<00:03, 20936.84it/s]\r",
      " 78%|███████▊  | 260944/336172 [00:13<00:03, 20947.47it/s]\r",
      " 78%|███████▊  | 263046/336172 [00:13<00:03, 20966.89it/s]\r",
      " 79%|███████▉  | 265143/336172 [00:13<00:03, 20951.32it/s]\r",
      " 79%|███████▉  | 267249/336172 [00:13<00:03, 20983.18it/s]\r",
      " 80%|████████  | 269348/336172 [00:13<00:03, 20963.53it/s]\r",
      " 81%|████████  | 271449/336172 [00:13<00:03, 20975.19it/s]\r",
      " 81%|████████▏ | 273547/336172 [00:13<00:02, 20952.03it/s]\r",
      " 82%|████████▏ | 275646/336172 [00:14<00:02, 20963.17it/s]\r",
      " 83%|████████▎ | 277744/336172 [00:14<00:02, 20966.09it/s]\r",
      " 83%|████████▎ | 279848/336172 [00:14<00:02, 20987.41it/s]\r",
      " 84%|████████▍ | 281947/336172 [00:14<00:02, 20984.80it/s]\r",
      " 84%|████████▍ | 284046/336172 [00:14<00:02, 20961.70it/s]\r",
      " 85%|████████▌ | 286151/336172 [00:14<00:02, 20986.70it/s]\r",
      " 86%|████████▌ | 288251/336172 [00:14<00:02, 20989.92it/s]\r",
      " 86%|████████▋ | 290368/336172 [00:14<00:02, 21043.06it/s]\r",
      " 87%|████████▋ | 292476/336172 [00:14<00:02, 21053.09it/s]\r",
      " 88%|████████▊ | 294582/336172 [00:14<00:01, 21034.35it/s]\r",
      " 88%|████████▊ | 296686/336172 [00:15<00:01, 21016.50it/s]\r",
      " 89%|████████▉ | 298788/336172 [00:15<00:01, 20986.87it/s]\r",
      " 90%|████████▉ | 300887/336172 [00:15<00:01, 20978.87it/s]\r",
      " 90%|█████████ | 302988/336172 [00:15<00:01, 20985.26it/s]\r",
      " 91%|█████████ | 305087/336172 [00:15<00:01, 20979.31it/s]\r",
      " 91%|█████████▏| 307188/336172 [00:15<00:01, 20986.85it/s]\r",
      " 92%|█████████▏| 309287/336172 [00:15<00:01, 20963.88it/s]\r",
      " 93%|█████████▎| 311384/336172 [00:15<00:01, 20964.07it/s]\r",
      " 93%|█████████▎| 313481/336172 [00:15<00:01, 20957.06it/s]\r",
      " 94%|█████████▍| 315577/336172 [00:15<00:00, 20929.16it/s]\r",
      " 94%|█████████▍| 317670/336172 [00:16<00:00, 20921.84it/s]\r",
      " 95%|█████████▌| 319764/336172 [00:16<00:00, 20927.21it/s]\r",
      " 96%|█████████▌| 321857/336172 [00:16<00:00, 20908.98it/s]\r",
      " 96%|█████████▋| 323948/336172 [00:16<00:00, 20902.26it/s]\r",
      " 97%|█████████▋| 326039/336172 [00:16<00:00, 20903.40it/s]\r",
      " 98%|█████████▊| 328142/336172 [00:16<00:00, 20941.30it/s]\r",
      " 98%|█████████▊| 330243/336172 [00:16<00:00, 20960.93it/s]\r",
      " 99%|█████████▉| 332347/336172 [00:16<00:00, 20984.07it/s]\r",
      " 99%|█████████▉| 334446/336172 [00:16<00:00, 20966.29it/s]\r",
      "100%|██████████| 336172/336172 [00:17<00:00, 19733.71it/s]\n"
     ]
    }
   ],
   "source": [
    "word_embeddings(18,w18_p1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "kSuRHKu88n9MwWVM4cjSAo",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": [
    "#read the processed file with both network similarity and language similarity\n",
    "#week = 18\n",
    "#part = 1\n",
    "#file_path1 = 'bothSim_Processed/mayjune_w' + str(week) + '_part'+str(part)+'_processed.parquet'\n",
    "#test = pd.read_parquet(file_path1)\n",
    "#test.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "datalore": {
     "hide_input_from_viewers": true,
     "hide_output_from_viewers": true,
     "node_id": "BWDjEEx0LOUukY6o98UJJ7",
     "type": "CODE"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "datalore": {
   "computation_mode": "JUPYTER",
   "packages": [],
   "report_row_ids": [],
   "version": 3
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
